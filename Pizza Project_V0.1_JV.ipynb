{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207- Applied Machine Learning - Section 1\n",
    "\n",
    "## Title: Random Acts of Pizza\n",
    "\n",
    "## Team 2: Sartaj Singh Baveja, Tim Spittle, Jay Venkata & Angela Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "\n",
    "1. [Overview](#overview)\n",
    "2. [Data Preparation](#dataprep)  \n",
    "2.1 [Initial Loading](#loading)  \n",
    "2.2 [Data Cleaning](#datacleaning)\n",
    "3. [Exploratory Data Analysis](#eda)  \n",
    "3.1 [Features of Interest](#featinterest)  \n",
    "3.2 [Variable correlation plot](#corrplot)  \n",
    "3.3 [Request Time Variables](#time)  \n",
    "3.4 [Requester Profile Variables](#profile)  \n",
    "3.5 [Textual Features](#textual)  \n",
    "4. [Baseline Model](#baseline)  \n",
    "4.1 [ZeroR Baseline](#bzeroR)  \n",
    "4.2 [NaiveBayes Baseline](#bnb)  \n",
    "4.3 [Logistic Regression Baseline](#blr)  \n",
    "4.4 [XGBoost Baseline](#bxg)  \n",
    "5. [Feature Engineering](#featengg)  \n",
    "5.1 [Time](#fe_time)  \n",
    "5.2 [Requester Profile Variables](#fe_reqprofile)  \n",
    "5.3 [Textual Features](#fe_textual)  \n",
    "6. [Model Selection](#models)  \n",
    "6.1 [Naive Bayes Model](#mnb)  \n",
    "6.2 [Logistic Regression model](#mlr)  \n",
    "6.3 [XGBoost Model](#mxg)  \n",
    "6.4 [Model Tuning](#tuning)  \n",
    "7. [Error Analysis](#error)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "\n",
    "This competition contains a dataset with textual requests for pizza from the Reddit community - Random Acts of Pizza (https://www.reddit.com/r/Random_Acts_Of_Pizza/) together with their outcome (successful/unsuccessful) and meta-data. \n",
    "\n",
    "The dataset includes 5671 requests collected from the Reddit community between December 8, 2010 and September 29, 2013 (retrieved on September 30, 2013). All requests ask for the same thing: a free pizza. The outcome of each request i.e whether its author received a pizza or not, is known. Meta-data includes information such as: time of the request, activity of the requester, community-age of the requester, etc.  \n",
    "\n",
    "**Outcome of Project**: By getting a sense of the dynamics and factors of a request that most likely would influence its success, the team hopes to build a model capable of predicting which requests will garner a cheesy (but sincere!) act of kindness and will result in a pizza purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dataprep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\manat\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\manat\\anaconda3\\lib\\site-packages (from wordcloud) (1.15.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\manat\\anaconda3\\lib\\site-packages (from wordcloud) (5.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\manat\\anaconda3\\lib\\site-packages (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\manat\\anaconda3\\lib\\site-packages (from nltk) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\manat\\anaconda3\\lib\\site-packages (0.82)\n",
      "Requirement already satisfied: scipy in c:\\users\\manat\\appdata\\roaming\\python\\python36\\site-packages (from xgboost) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\manat\\anaconda3\\lib\\site-packages (from xgboost) (1.15.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyenchant\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/54/04d88a59efa33fefb88133ceb638cdf754319030c28aadc5a379d82140ed/pyenchant-2.0.0.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\manat\\AppData\\Local\\Temp\\pip-install-2fi5dpkk\\pyenchant\\setup.py\", line 212, in <module>\n",
      "        import enchant\n",
      "      File \"C:\\Users\\manat\\AppData\\Local\\Temp\\pip-install-2fi5dpkk\\pyenchant\\enchant\\__init__.py\", line 92, in <module>\n",
      "        from enchant import _enchant as _e\n",
      "      File \"C:\\Users\\manat\\AppData\\Local\\Temp\\pip-install-2fi5dpkk\\pyenchant\\enchant\\_enchant.py\", line 145, in <module>\n",
      "        raise ImportError(msg)\n",
      "    ImportError: The 'enchant' C library was not found. Please install it via your OS package manager, or use a pre-built binary wheel from PyPI.\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\manat\\AppData\\Local\\Temp\\pip-install-2fi5dpkk\\pyenchant\\\n",
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install xgboost\n",
    "# !{sys.executable} -m pip install graphviz\n",
    "# !{sys.executable} -m conda install graphviz\n",
    "!{sys.executable} -m pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\manat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manat\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'enchant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f19a2f3a5153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0menchant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchecker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'enchant'"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "## Reference: https://gist.github.com/rspeare/77061e6e317896be29c6de9a85db301d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import scipy.stats as stat\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "# SK Learn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/index.html\n",
    "import xgboost as xgb\n",
    "\n",
    "# Source : https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
    "# NMF (Non-Negative Matrix Factorization) to understand topic breakdown\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "### New packages\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from enchant.checker import SpellChecker\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in pizza_request_dataset.json corresponds to one request (the first and only request by the requester).\n",
    "\n",
    "### Fields in each request\n",
    "\n",
    "| Field Name | Description |\n",
    "| ---------- | ----------- |\n",
    "| giver_username_if_known | Reddit username of giver if known, i.e. the person satisfying the request (\"N/A\" otherwise). |\n",
    "| in_test_set | Boolean indicating whether this request was part of our test set. |\n",
    "| number_of_downvotes_of_request_at_retrieval | Number of downvotes at the time the request was collected. |\n",
    "| number_of_upvotes_of_request_at_retrieval | Number of upvotes at the time the request was collected. |\n",
    "| post_was_edited | Boolean indicating whether this post was edited (from Reddit). |\n",
    "| request_id | Identifier of the post on Reddit, e.g. \"t3_w5491\". |\n",
    "| request_number_of_comments_at_retrieval | Number of comments for the request at time of retrieval. |\n",
    "| request_text | Full text of the request. |\n",
    "| request_text_edit_aware | Edit aware version of \"request_text\". We use a set of rules to strip edited comments indicating the success of the request such as \"EDIT: Thanks /u/foo, the pizza was delicous\". |\n",
    "| request_title | Title of the request. |\n",
    "| requester_account_age_in_days_at_request | Account age of requester in days at time of request. |\n",
    "| requester_account_age_in_days_at_retrieval | Account age of requester in days at time of retrieval. |\n",
    "| requester_days_since_first_post_on_raop_at_request | Number of days between requesters first post on RAOP and this request (zero if requester has never posted before on RAOP). |\n",
    "| requester_days_since_first_post_on_raop_at_retrieval | Number of days between requesters first post on RAOP and time of retrieval. |\n",
    "| requester_number_of_comments_at_request | Total number of comments on Reddit by requester at time of request. |\n",
    "| requester_number_of_comments_at_retrieval | Total number of comments on Reddit by requester at time of retrieval. |\n",
    "| requester_number_of_comments_in_raop_at_request | Total number of comments in RAOP by requester at time of request. |\n",
    "| requester_number_of_comments_in_raop_at_retrieval | Total number of comments in RAOP by requester at time of retrieval. |\n",
    "| requester_number_of_posts_at_request | Total number of posts on Reddit by requester at time of request. |\n",
    "| requester_number_of_posts_at_retrieval | Total number of posts on Reddit by requester at time of retrieval. |\n",
    "| requester_number_of_posts_on_raop_at_request | Total number of posts in RAOP by requester at time of request. |\n",
    "| requester_number_of_posts_on_raop_at_retrieval | Total number of posts in RAOP by requester at time of retrieval. |\n",
    "| requester_number_of_subreddits_at_request | The number of subreddits in which the author had already posted in at the time of request. |\n",
    "| requester_received_pizza | Boolean indicating the success of the request, i.e., whether the requester received pizza. |\n",
    "| requester_subreddits_at_request | The list of subreddits in which the author had already posted in at the time of request. |\n",
    "| requester_upvotes_minus_downvotes_at_request | Difference of total upvotes and total downvotes of requester at time of request. |\n",
    "| requester_upvotes_minus_downvotes_at_retrieval | Difference of total upvotes and total downvotes of requester at time of retrieval. |\n",
    "| requester_upvotes_plus_downvotes_at_request | Sum of total upvotes and total downvotes of requester at time of request. |\n",
    "| requester_upvotes_plus_downvotes_at_retrieval | Sum of total upvotes and total downvotes of requester at time of retrieval. |\n",
    "| requester_user_flair | Users on RAOP receive badges (Reddit calls them flairs) which is a small picture next to their username. In our data set the user flair is either None (neither given nor received pizza, N=4282), \"shroom\" (received pizza, but not given, N=1306), or \"PIF\" (pizza given after having received, N=83). |\n",
    "| requester_username | Reddit username of requester. |\n",
    "| unix_timestamp_of_request | Unix timestamp of request (supposedly in timezone of user, but in most cases it is equal to the UTC timestamp -- which is incorrect since most RAOP users are from the USA). |\n",
    "| unix_timestamp_of_request_utc | Unit timestamp of request in UTC. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initial Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training data in JSON\n",
    "#os.chdir(\"/Users/jayvenkata/Documents/W207- Applied Machine Learning/Projects/Group Project\")\n",
    "with open(os.path.join(os.getcwd(), 'train.json')) as org_train_data_file:    \n",
    "    org_train_data = json.load(org_train_data_file)\n",
    "\n",
    "## Load the test data in JSON\n",
    "with open(os.path.join(os.getcwd(), 'test.json')) as org_test_data_file:    \n",
    "    org_test_data = json.load(org_test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data in JSON to pandas dataframe\n",
    "org_train_df_raw = pd.io.json.json_normalize(org_train_data)\n",
    "org_train_df = pd.DataFrame.from_records(org_train_data)\n",
    "# org_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we split our data into training and development. Further, we make sure that both sets mirror the average success rate in our dataset of 24.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the original training data into training and development\n",
    "np.random.seed(0)\n",
    "train_df, dev_df = train_test_split(org_train_df, test_size = 0.4, stratify=org_train_df['requester_received_pizza'])\n",
    "\n",
    "train_labels = train_df.requester_received_pizza.astype(int).values\n",
    "dev_labels = dev_df.requester_received_pizza.astype(int).values\n",
    "\n",
    "## Verify the stratefication works\n",
    "print(\"Sucess Rate (training data): \" + str(round(train_df[\"requester_received_pizza\"].mean(),2)))\n",
    "print(\"Sucess Rate (dev data): \" + str(round(dev_df[\"requester_received_pizza\"].mean(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test data in JSON to pandas dataframe\n",
    "test_df = pd.DataFrame.from_records(org_test_data)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = list(train_df.columns.values)\n",
    "test_columns = list(test_df.columns.values)\n",
    "\n",
    "var_table_overlap = pd.DataFrame(columns = ['Variable', 'Train', 'Test'])\n",
    "train_var_series = pd.Series(train_columns, name='Variable')\n",
    "test_var_series = train_var_series.isin(test_columns)\n",
    "var_table_overlap['Variable'] = train_columns\n",
    "var_table_overlap['Train'] = True\n",
    "var_table_overlap['Test'] = test_var_series\n",
    "var_table_overlap.sort_values(by = ['Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we will focus only on the columns that are present in both the datasets and disregard the others. This is because\n",
    "- *_at_retrieval doesn't relate to the concept of real-time as much as *_at_request variables do\n",
    "- user_flair not required since this is after / we have received_pizza variable\n",
    "- post_was_edited / request_text - better variable is the request_text_edit_aware since it captures the text even when a post is edited\n",
    "- requester_received_pizza - that's the variable that needs to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the training data\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the development data\n",
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datacleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "From the plot below, we notice outliers where number of upvotes & downvotes are higher than 400,000. Hence we decide to take out these outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.loc[:,'requester_upvotes_plus_downvotes_at_request']).set_title('Distribution Plot of Upvotes & Downvotes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.nlargest(3, 'requester_upvotes_plus_downvotes_at_request')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such a long right tail and the person with the most up_plus_down is not even the most frequent poster or oldest account, just a troll. Remove\n",
    "print(train_df.shape)\n",
    "train_df = train_df[train_df.requester_upvotes_plus_downvotes_at_request != 789287]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Received as numeric\n",
    "train_df['requester_received_pizza_int'] = train_df.requester_received_pizza.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"featinterest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Read through EDA 3.1 & align with sections below\n",
    "\n",
    "### 3.1 Features of Interest\n",
    "\n",
    "Success of these reddit requests depend on factors like who is asking, how they are asking, and when are they asking. This will help us understand the attributes of the best formulated requests and why certain ones are promoted higher than others.\n",
    "\n",
    "#### Meta-Data Features\n",
    "\n",
    "_General Note_ Many features not present in test data are not known at time of posting, therefore they will be ignored for this analysis. This includes the \"at retrieval\" statistics, RAOP \"user flair\", and raw (i.e. non-\"edit aware\") request text.  \n",
    "\n",
    "**Time**  \n",
    "Time is a very basic but important feature to include. Logically, there are likely times of day when more users are active on RAOP and this may have varied effects on the behaviors we observe:  \n",
    "- More users requesting may make the environment more competitive (i.e. harder for a single post to stand out) \n",
    "- Conversely, more users giving may make likelihood of success higher (all things equal).  \n",
    "    - _NOTE_, however, that we cannot observe the time of giving in this dataset.  \n",
    "\n",
    "These periods of increased requests/gives may not coincide with one another and it will be important to understand the periods of high and low activity relative to UTC; there may be multiple shifts throughout a day coinciding with higher activity in different countries/time zones around the globe.  \n",
    "\n",
    "**Requester Profile**    \n",
    "In attempting to predict likelihood of fulfillment for a request on RAOP based on featues related to the profile of the requester, we believe it may be important to make a distinction between: \n",
    "- _Primary_ profile features (i.e. features which an average reader/potential giver on RAOP may see/consider)\n",
    "    - Age of account - whether it appears to be a new/throwaway account or a longtime veteran  \n",
    "    - Number and frequency of requests - if the requester has made requests before\n",
    "- _Secondary_ features (i.e. extended detail about requester activity on Reddit that a potential giver might not see, and therefore it wouldn't have as much influence on their likelihood of fulfilling the request or not)  \n",
    "    - Comments made\n",
    "    - Posts\n",
    "    - Sub-Reddits in which they participate\n",
    "    - Upvotes/Downvotes\n",
    "\n",
    "**Community Effects (Secondary)**  \n",
    "The training data constains featues related to the reactions to a request on RAOP (upvotes/downvotes/comments) which, while not available in the test data and not appropriate for success classifcation algorithm (given that we don't know this info at time of the request nor do we know if this activity happened before/after the request was fulfilled), positive or contentious reactions to posts may be correlated with success/fulfillment. Therefore, it may be worhtwhile to explore these relationships and, if useful, a sensitivity analysis that predicts these metrics to provide additional insight into predictive features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"corrplot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Variable correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with only the shared columns\n",
    "train_w_test = train_df[test_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "train_w_test['requester_received_pizza'] = train_df['requester_received_pizza']\n",
    "corr = train_w_test.corr()\n",
    "sns.heatmap(corr, \n",
    "            mask=np.zeros_like(corr, dtype = np.bool), \n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap = True),\n",
    "            square=True, \n",
    "            ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "1. Request timing- Day of the week and time of the day\n",
    "2. Text Field length\n",
    "3. Upvotes vs Downvotes  \n",
    "4. Requester account vs activity - evaluate the various requester feature differences between those whose requests were fulfilled, and those whose requests were not\n",
    "5. Perform Topic Modeling using LDA or NMF to identify most common topics and then, we'll be able to group them into categories (https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730) \n",
    "6. Word clouds around successful/unsuccessful words  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"time\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Request Time Variables\n",
    "\n",
    "Let's break down Request Time into 4 Trends and do a deeper dive into each of these: \n",
    "\n",
    "1. Frequency of Requests over Months\n",
    "2. Fulfillment of Requests over Months\n",
    "3. Fulfillment - Day of the Week\n",
    "4. Fulfillment - Time of the Day\n",
    "\n",
    "#### 1. Frequency of Requests over Months\n",
    "\n",
    "This would show us how many requests for Pizza posts occurred over the entire duration of the dataset between 2011 and 2013. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['datetime'] = pd.to_datetime(train_df[\"unix_timestamp_of_request\"], unit = 's')\n",
    "d.index = d['datetime']\n",
    "d['datetime'].resample('W').count().plot().set_title('Number of Posts Across the Entire Dataset- 2011 to 2013')\n",
    "plt.xlabel('Month & Year in the Dataset')\n",
    "plt.ylabel('Number of Posts/ Requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above graph that there were a lot of posts around the 6 month mark of the reddit community opening until about July 2011. There also seems to be a spike towards the end of the dataset- July & August 2013. \n",
    "\n",
    "#### 2. Fulfillment of Requests over Months\n",
    "\n",
    "This would show us how many Pizza givers there were over the entire duration of the dataset between 2011 and 2013. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['datetime'] = pd.to_datetime(train_df[\"unix_timestamp_of_request\"], unit = 's')\n",
    "train_labels = train_df[\"requester_received_pizza\"]\n",
    "d['result'] = train_labels\n",
    "d.index = d['datetime']\n",
    "d.resample('W').mean().plot().set_title(\"Percentage of Pizza Requests Fulfilled Across the Dataset\")\n",
    "plt.xlabel('Month & Year in the Dataset')\n",
    "plt.ylabel('Percentage of Fulfilled Requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that request fulfillment was at its highest at the start of the group. However despite a few peaks during the Winter (Dec-Jan season) the overall fulfillment % has fallen over time. This shows that people are more willing to give during the Holiday season.\n",
    "\n",
    "#### 3. Day of the Week \n",
    "\n",
    "Let's now look into whether the Day of the Week played a role in Pizza request fulfillments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "d['Day_of_Week'] = d['datetime'].dt.weekday_name\n",
    "week_df = d.groupby('Day_of_Week').agg(['mean', 'count']).reindex(days)\n",
    "week_df ### NOTE ### - just returning pandas dataframe has cleaner output than wrapping in print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fulfillment rate varies between 21.7% (Wednesday) to 30.2% (Thursday). \n",
    "This seems like a reasonably distinguishing feature that should be considered for our model. \n",
    "\n",
    "#### 4. Time of the Day\n",
    "\n",
    "Let's now look into whether the Time of the Day played a role in Pizza request fulfillments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['hour'] = d['datetime'].dt.hour\n",
    "d[['hour', 'result']].groupby('hour').agg('count').plot().set_title(\"Number of Requests through the course of 24 Hour Day\")\n",
    "plt.xlabel('Hour of the Day (0-24 Hours)')\n",
    "plt.ylabel('Number of Requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above graph that the number of posts/ requests spikes up considerably during the night times- Between 8 PM and 3 AM with a peak around Midnight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d[['hour', 'result']].groupby('hour').agg('mean').plot().set_title(\"Requests Fulfilled over the course of the Day\")\n",
    "plt.xlabel('Hour of the Day (0-24 Hours)')\n",
    "plt.ylabel('Percentage of Fulfilled Requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above graph that the number of fulfilled requests varies from 6% to 38% depending on the time of the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Visualize requests and granted requests over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data setup\n",
    "train_w_test = train_w_test.assign(\n",
    "    unix_timestamp_of_request = pd.to_datetime(\n",
    "        train_w_test.unix_timestamp_of_request, unit = \"s\"),\n",
    "    unix_timestamp_of_request_utc = pd.to_datetime(\n",
    "        train_w_test.unix_timestamp_of_request_utc, unit = \"s\"))\n",
    "\n",
    "ts = pd.DataFrame({'granted requests':train_df.requester_received_pizza.tolist(),\n",
    "                  'requests':[1] * train_df[['requester_received_pizza']].shape[0]},\n",
    "                  index = train_w_test.unix_timestamp_of_request.dt.date.tolist())\n",
    "\n",
    "ts = ts.groupby(ts.index).sum()\n",
    "\n",
    "ts_month = pd.DataFrame({'granted requests':train_df.requester_received_pizza.tolist(),\n",
    "                  'requests':[1] * train_df[['requester_received_pizza']].shape[0]},\n",
    "                index = (train_w_test.unix_timestamp_of_request.dt.date + pd.offsets.MonthBegin(0)).tolist())\n",
    "\n",
    "ts_month = ts_month.groupby(ts_month.index).sum()\n",
    "\n",
    "# Plots\n",
    "# 1. By day\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(ts)\n",
    "plt.title(\"Number of requests and granted requests per day\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. By Month\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(ts_month)\n",
    "plt.title(\"Number of requests and granted requests per month\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. By Month (proportion)\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(ts_month.assign(prop_granted = ts_month['granted requests'] / ts_month['requests'])['prop_granted'])\n",
    "plt.title(\"proportion of requests granter per month\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# TO DO: INclude PLOT LEGEND: Explain Blue & Orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"profile\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Requester Profile Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profile = pd.DataFrame({'received':train_df.requester_received_pizza_int.tolist(),\n",
    "                              'account_age':train_df.requester_account_age_in_days_at_request.tolist(),\n",
    "                              'days_since_first_request':train_df.requester_days_since_first_post_on_raop_at_request.tolist()})\n",
    "\n",
    "sns.pairplot(train_profile).set_title('Scatterplot of request profile variables');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- Interesting that there are many 0-day accounts and first time posters\n",
    "    - For account age we might want to isolate 0 and then stratify by a few key buckets (max of 8 years is a long time)\n",
    "    - For days_since_post defintely create first time vs repeat\n",
    "        - Also take a look at long right tail (500 seems very high)\n",
    "- Floor on mid-right plot shows that some people post to raop on first day of account then continue on until posting again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments, Reddit and RAOP (not posts - it aligns too much with days since last post, very few observations)\n",
    "# Up/Down Votes\n",
    "train_part = pd.DataFrame({'received':train_df.requester_received_pizza_int.tolist(),\n",
    "                           'comments_raop':train_df.requester_number_of_comments_in_raop_at_request.tolist(),\n",
    "                           'comments_reddit':train_df.requester_number_of_comments_at_request.tolist(),\n",
    "                           'up_plus_down':train_df.requester_upvotes_plus_downvotes_at_request.tolist(),\n",
    "                           'up_minus_down':train_df.requester_upvotes_minus_downvotes_at_request.tolist()})\n",
    "\n",
    "sns.pairplot(train_part).set_title('Scatterplot of request profile variables');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- Lurkers: \n",
    "    - Tons of 0 values on participation metrics\n",
    "    - Big leading spike in comments relative to up/downvotes makes sense - must comment many times before receiving a lot of attention \n",
    "- Only noticeable correlation with received is RAOP participation\n",
    "    - Comments in RAOP not particularly correlated with comments outside of RAOP (justification for focusing exclusively on RAOP participation metrics!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"textual\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Textual Features\n",
    "\n",
    "#### a) Non Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Stanford Paper**\n",
    "\n",
    "To identify the different kinds of stories we draw on previous literature suggesting that narratives can be automatically extracted using topic modeling and related techniques. We therefore perform topic modeling through non negative matrix factorization (NMF) of a TF-IDF weighted bag-of-words representation of the requests in our dataset.\n",
    "\n",
    "We additionally enforce sparsity on the topic distribution for each request to shape the topics in a way that captures most of a given request, and restrict ourselves to nouns. We choose to use 10 topics and use a SVD-based initialization for NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, \n",
    "                                   min_df=2, \n",
    "                                   max_features=1000, \n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(train_df['request_text_edit_aware'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "nmf = NMF(n_components=10, \n",
    "          random_state=1, \n",
    "          alpha=0.1, \n",
    "          l1_ratio=0.5, \n",
    "          init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Print the 5 most common topics with their count\n",
    "topics_vector = np.argmax(nmf.transform(tfidf), axis=1)\n",
    "top_5 = Counter(topics_vector).most_common(5)\n",
    "print('Top five most common topics with counts: {}'.format(str(top_5)))\n",
    "\n",
    "# Display topics with the top 10 words in each topic\n",
    "def display_topics(model, feature_names, no_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic {}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_words - 1:-1]]))\n",
    "\n",
    "display_topics(nmf, tfidf_feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top 5 topics can be put under the following categories\n",
    "- Topic 0: Job\n",
    "- Topic 1: Pizza / Craving\n",
    "- Topic 3: Reciprocity\n",
    "- Topic 8: Money\n",
    "- Topic 2: Proof / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "LDA is based on probabilistic graphical modeling while NMF relies on linear algebra.\n",
    "\n",
    "A tf-idf transformer is applied to the bag of words matrix that NMF must process with the TfidfVectorizer. LDA on the other hand, being a probabilistic graphical model (i.e. dealing with probabilities) only requires raw counts, so a CountVectorizer is used. Stop words are removed and the number of terms included in the bag of words matrix is restricted to the top 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source : https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic {}\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df = 0.95, \n",
    "                                min_df = 2, \n",
    "                                max_features = 1000, \n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(train_df['request_text_edit_aware'].tolist())\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=10, \n",
    "                                max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,\n",
    "                                random_state=0).fit(tf)\n",
    "\n",
    "# Print the 5 most common topics with their count\n",
    "topics_vector = np.argmax(lda.transform(tf), axis=1)\n",
    "top_5 = Counter(topics_vector).most_common(5)\n",
    "print('Top five most common topics with counts: {}'.format(str(top_5)))\n",
    "\n",
    "no_top_words = 15\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top 5 topics can be put under the following categories\n",
    "- Topic 0: Money / Job\n",
    "- Topic 9: Money / Job\n",
    "- Topic 3: Verification\n",
    "- Topic 5: Pizza\n",
    "- Topic 2: General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Word Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this, we want to visualize the common bigrams and compare them for successful and unsuccessful requests. We choose bigrams as unigrams alone makes little sense and trigrams are too rare to be useful. From these visuals we can start to get an idea of potential differentiatiors in terms of post content that might make a difference to whether a user gets pizza or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "def word_join(string,joiner=' '):\n",
    "    return joiner.join(string.split())\n",
    "\n",
    "joined_words = np.vectorize(word_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WordCloud for Successful Requests\n",
    "\n",
    "# Get text from variables where received pizza val was true\n",
    "successful_edit_text = train_df[train_df['requester_received_pizza'] == True]['request_text_edit_aware']\n",
    "\n",
    "CV = CountVectorizer(stop_words='english',ngram_range=(2,2))\n",
    "cv_fit = CV.fit_transform(successful_edit_text)\n",
    "\n",
    "vocab = joined_words(CV.get_feature_names())\n",
    "\n",
    "frequency = list(cv_fit.toarray().sum(axis=0))\n",
    "word_score = dict(zip(vocab,frequency))\n",
    "wc = WordCloud(max_words = 200,\n",
    "               stopwords = set(STOPWORDS),\n",
    "               height = 500,\n",
    "               width = 800).fit_words(word_score)\n",
    "\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "\n",
    "sorted_word_score = sorted(list(zip(vocab,frequency)), key=lambda x: -x[1])\n",
    "got_pizza = pd.DataFrame(sorted_word_score[:20], columns = ['Word', 'Freq'])\n",
    "got_pizza.plot.bar(x = 'Word', y = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from variables where received pizza val was true\n",
    "unsuccessful_edit_text = train_df[train_df['requester_received_pizza'] == False]['request_text_edit_aware']\n",
    "\n",
    "CV2 = CountVectorizer(stop_words='english',ngram_range=(2,2))\n",
    "cv_fit2 = CV2.fit_transform(unsuccessful_edit_text)\n",
    "\n",
    "vocab2 = joined_words(CV2.get_feature_names())\n",
    "\n",
    "frequency2 = list(cv_fit2.toarray().sum(axis=0))\n",
    "word_score2 = dict(zip(vocab2,frequency2))\n",
    "wc2 = WordCloud(max_words = 200,\n",
    "                stopwords = set(STOPWORDS),\n",
    "                height = 500,\n",
    "                width = 800).fit_words(word_score2)\n",
    "\n",
    "plt.imshow(wc2, interpolation='bilinear')\n",
    "\n",
    "sorted_word_score2 = sorted(list(zip(vocab2,frequency2)), key=lambda x: -x[1])\n",
    "no_pizza = pd.DataFrame(sorted_word_score2[:20], columns = ['Word', 'Freq'])\n",
    "no_pizza.plot.bar(x = 'Word', y = 'Freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting differences such as amongst common phrases, what's interesting is how those who didn't get pizza mentioned \"love pizza\" and \"pay forward\" more often. Further, they also include images in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) From the above, look at unigrams now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "granted_requests = train_df[train_df['requester_received_pizza'] == True]\n",
    "ungranted_requests = train_df[train_df['requester_received_pizza'] == False]\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wc2 = WordCloud(max_words = 200,\n",
    "               height = 500,\n",
    "               width = 800).fit_words(word_score2)\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      max_words=300,\n",
    "                      max_font_size=50, \n",
    "                      random_state=42).generate(str(granted_requests['request_text_edit_aware']))\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud for Granted Requests\")\n",
    "plt.show()\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      max_words=300,\n",
    "                      max_font_size=50, \n",
    "                      random_state=42).generate(str(ungranted_requests['request_text_edit_aware']))\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud for Ungranted Requests\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"baseline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO ###: \n",
    "    # Normalize continuous values- Upvotes vs Downvotes. Not a priority\n",
    "\n",
    "# Use standard CountVectorizer to transform the training data and dev data \n",
    "vectorizer = CountVectorizer() \n",
    "train_data = vectorizer.fit_transform(train_df['request_text_edit_aware'])\n",
    "dev_data = vectorizer.transform(dev_df['request_text_edit_aware'])\n",
    "\n",
    "list_vars_keep = ['requester_upvotes_plus_downvotes_at_request', \n",
    "                  'requester_upvotes_minus_downvotes_at_request',\n",
    "                  'requester_number_of_comments_in_raop_at_request',\n",
    "                  'unix_timestamp_of_request',\n",
    "                  'requester_days_since_first_post_on_raop_at_request',\n",
    "                  'requester_account_age_in_days_at_request']\n",
    "\n",
    "train_df_lim = train_df[list_vars_keep]\n",
    "train_text_df = pd.DataFrame(train_data.toarray())\n",
    "train_concat = pd.concat([train_df_lim.reset_index(), train_text_df], axis = 1)\n",
    "train_concat = train_concat.drop(columns = ['index'])\n",
    "\n",
    "dev_df_lim = dev_df[list_vars_keep]\n",
    "dev_text_df = pd.DataFrame(dev_data.toarray())\n",
    "dev_concat = pd.concat([dev_df_lim.reset_index(), dev_text_df], axis = 1)\n",
    "dev_concat = dev_concat.drop(columns = ['index'])\n",
    "\n",
    "print(train_df_lim.shape)\n",
    "print(train_text_df.shape)\n",
    "print(train_concat.shape)\n",
    "\n",
    "print(dev_df_lim.shape)\n",
    "print(dev_text_df.shape)\n",
    "print(dev_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(dev_labels, pred_dev_prob):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(dev_labels, pred_dev_prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def confusion_plot(confusion_matrix, target_names):\n",
    "    \n",
    "    # Plot confusion matrix (via imshow)\n",
    "    plt.imshow(confusion_matrix, interpolation = \"nearest\", cmap = plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Loop through each value of the matrix to add data labels\n",
    "    width, height = confusion_matrix.shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(confusion_matrix[x][y]), xy = (y, x), \n",
    "                        horizontalalignment = \"center\",\n",
    "                        verticalalignment = \"center\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    \n",
    "def standard_output(labels_in, pred_prob_in, pred_class_in):\n",
    "    # AUC\n",
    "    print(\"AUC score = {} \\n\".format(roc_auc_score(labels_in, pred_class_in, average = 'micro')))\n",
    "    # Classification Report\n",
    "    print(classification_report(labels_in, pred_class_in))\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1,2,1)\n",
    "    confusion_plot(confusion_matrix = confusion_matrix(y_true = labels_in, \n",
    "                                                       y_pred = pred_class_in), \n",
    "                   target_names = [\"No Pizza\", \"Pizza\"])\n",
    "    # ROC\n",
    "    plt.subplot(1,2,2)\n",
    "    roc_plot(labels_in, pred_prob_in)\n",
    "    \n",
    "### TO DO ### \n",
    "    # - Suppress Warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bzeroR\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - ZeroR Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero R rule = apply highest class % to all  \n",
    "(No pizza received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_labels vs. vector of 1/0 based on guessing all 1/0 (majority %)\n",
    "zeror_prob = np.repeat(train_df[\"requester_received_pizza\"].mean(), len(dev_labels))\n",
    "zeror_class = np.repeat(round(train_df[\"requester_received_pizza\"].mean(),0), len(dev_labels))\n",
    "\n",
    "standard_output(labels_in = dev_labels, pred_prob_in = zeror_prob, pred_class_in = zeror_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bnb\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 NaiveBayes Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    # Create MultinomialNB\n",
    "    mnb = MultinomialNB()\n",
    "\n",
    "    # test the best value for alpha\n",
    "    parameters = {'alpha': np.linspace(0.01, 10, 100)}\n",
    "\n",
    "    # create GridSearchCV to find the best alpha\n",
    "    clf = GridSearchCV(mnb, parameters)\n",
    "\n",
    "    # train the MultinomialNB\n",
    "    clf.fit(train_data, train_labels)\n",
    "\n",
    "    pred_dev_prob = clf.predict_proba(dev_data)[:,0]\n",
    "    pred_dev_labels = clf.predict(dev_data)\n",
    "\n",
    "#     print(clf.best_params_)\n",
    "#     print(\"AUC score = {} \\n\".format(roc_auc_score(dev_labels, pred_dev_prob, average='micro')))\n",
    "#     print(classification_report(dev_labels, pred_dev_labels))\n",
    "#     print(\"Confusion Matrix \\n{}\".format(confusion_matrix(dev_labels, pred_dev_labels)))\n",
    "#     roc_plot(dev_labels, pred_dev_prob)\n",
    "#     accuracy = round(metrics.accuracy_score(dev_labels, pred_dev_labels),2)\n",
    "#     print(accuracy)\n",
    "    \n",
    "    standard_output(labels_in = dev_labels, \n",
    "                    pred_prob_in = pred_dev_prob, \n",
    "                    pred_class_in = pred_dev_labels)\n",
    "    \n",
    "NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an auc of .5, the Naive Bayes baseline model does similar than randomly guessing (auc of .5). \n",
    "The confusion matrix shows that the model fails to predict any fulfilled requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"blr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's leverage the Standard CountVectorizer transformations done during the Naive Bayes Baseline above\n",
    "#train_data/ train_labels & dev_data/ dev_labels\n",
    "\n",
    "#Create Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_data,train_labels)\n",
    "logit_preds = log_reg.predict(dev_data)\n",
    "logit_dev_prob = log_reg.predict_proba(dev_data)[:,0]\n",
    "\n",
    "log_scores = [] \n",
    "log_scores.append(metrics.f1_score(dev_labels, logit_preds, average='micro'))\n",
    "\n",
    "log_weights = [] #For the sum of the squared weight values \n",
    "log_weights.append(np.sum(log_reg.coef_**2))\n",
    "\n",
    "print(\"Logistic Baseline: the best f1 score =\",\"{:.4f}\".format(np.max(log_scores)),\"\\n\")\n",
    "print(\"Value of Sum of squared weight Value is =\",\"{:.1f}\".format(np.max(log_weights)),\"\\n\")\n",
    "print(\"AUC score = {} \\n\".format(roc_auc_score(dev_labels, logit_dev_prob, average='micro')),\"\\n\")\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(dev_labels, logit_preds)))\n",
    "roc_plot(dev_labels, logit_dev_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an auc of .44, the logistic baseline model does worse than randomly guessing (auc of .5). \n",
    "The confusion matrix shows that the model leans more towards the False positive than the True positive rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bxg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: can still use numeric/continuous variable\n",
    "train_xgb = xgb.DMatrix(train_concat, label = train_labels)\n",
    "dev_xgb = xgb.DMatrix(dev_concat)\n",
    "\n",
    "# Specify parameters via map\n",
    "xgb_params = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "xgb_num_round = 2\n",
    "xgb_base = xgb.train(xgb_params, train_xgb, xgb_num_round)\n",
    "\n",
    "# Prediction\n",
    "xgb_dev_prob = xgb_base.predict(dev_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.plot_tree(xgb_base, num_trees=1)\n",
    "### REQUIRES graphviz - http://www.graphviz.org/\n",
    "### TBD - still trying to figure out dependencies/PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_output(labels_in = dev_labels, pred_prob_in = xgb_dev_prob, pred_class_in = xgb_dev_prob.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"featengg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our final dataframes\n",
    "train_feat_mat = pd.DataFrame()\n",
    "dev_feat_mat = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vars_keep = ['requester_upvotes_plus_downvotes_at_request', \n",
    "                  'requester_upvotes_minus_downvotes_at_request',\n",
    "                  'requester_number_of_comments_in_raop_at_request',\n",
    "                  'unix_timestamp_of_request',\n",
    "                  'requester_days_since_first_post_on_raop_at_request',\n",
    "                  'requester_account_age_in_days_at_request']\n",
    "\n",
    "train_feat_mat = train_df[list_vars_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_time\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Time\n",
    "\n",
    "**A. 'During Initial Period': **\n",
    "\n",
    "The first two graphs in the Time Section indicate that during the initial period of the group, there was a burst of requests and an unsustained high rate of fulfillment. This doesn't align with the general trend. It might be interesting to analyze the differences between the Initial_period (Until July 2011) vs Not_Initial Period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(input_df, output_df):\n",
    "    cutoff_date = datetime.date(2011,7,31) # Cutting off on July 31\n",
    "    cutoff_time = time.mktime(cutoff_date.timetuple())\n",
    "    output_df['during_initial_period'] = np.where(input_df['unix_timestamp_of_request_utc'] < cutoff_time, 1, 0)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat = add_time_features(input_df = train_df,\n",
    "                                   output_df = train_feat_mat)\n",
    "\n",
    "dev_feat_mat = add_time_features(input_df = dev_df,\n",
    "                                 output_df = dev_feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. 'Time of Day' & 'Hour_of_Day': **\n",
    "\n",
    "The third graph in the Time Section indicate that fulfillment rates oscillate between 21% & 30% based on day of the week. This isn't significant enough to be considered a distinguishing feature.\n",
    "\n",
    "Time of the day provides an interesting variation between 6% and 38%. However posts from multiple days/ times are available for givers to select from an fulfill.  Hence this can't be used as a feature since it doesn't help us in identifying a characteristic of the Request Post. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_reqprofile\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Requester Profile Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_profile_features(input_df, output_df):\n",
    "    # Age of account\n",
    "    median_account_age_nonzero = input_df[input_df['requester_account_age_in_days_at_request']!=0]['requester_account_age_in_days_at_request'].median()\n",
    "    account_age_conditions = [\n",
    "        (input_df.loc[:,'requester_account_age_in_days_at_request']==0),\n",
    "        (input_df.loc[:,'requester_account_age_in_days_at_request']<=median_account_age_nonzero),\n",
    "        (input_df.loc[:,'requester_account_age_in_days_at_request']>median_account_age_nonzero)]\n",
    "    account_age_choices = ['throwaway', 'new', 'old']\n",
    "    \n",
    "    output_df['account_age_cat'] = np.select(account_age_conditions, account_age_choices, default='na')\n",
    "    output_df['old'] = np.where(output_df['account_age_cat']=='old', 1, 0)\n",
    "    output_df['new'] = np.where(output_df['account_age_cat']=='new', 1, 0)\n",
    "    output_df['throwaway'] = np.where(output_df['account_age_cat']=='throwaway', 1, 0)\n",
    "    \n",
    "    # Number and frequency of requests - if the requester has made requests before\n",
    "    output_df['first_repeat_requester'] = np.where(input_df['requester_days_since_first_post_on_raop_at_request']==0, 'first', 'repeat')\n",
    "    output_df['first_requester'] = np.where(output_df['first_repeat_requester']=='first', 1, 0)\n",
    "    output_df['repeat_requester'] = np.where(output_df['first_repeat_requester']=='repeat', 1, 0)\n",
    "\n",
    "    # Commenter\n",
    "    output_df['comments_raop_cat'] = np.where(input_df['requester_number_of_comments_in_raop_at_request']==0, 'never', 'has')\n",
    "    output_df['never_comments'] = np.where(output_df['comments_raop_cat']=='never', 1, 0)\n",
    "    output_df['has_commented'] = np.where(output_df['comments_raop_cat']=='has', 1, 0)\n",
    "    \n",
    "    # Up/Down Votes\n",
    "    output_df['up_plus_down_cat'] = np.where(input_df['requester_upvotes_plus_downvotes_at_request']==0, 'ignored', 'popular')\n",
    "    output_df['popular'] = np.where(input_df['requester_upvotes_plus_downvotes_at_request']!=0, 1, 0)\n",
    "    output_df['ignored'] = np.where(input_df['requester_upvotes_plus_downvotes_at_request']==0, 1, 0)\n",
    "    \n",
    "    # TO DO: consider using up_minus_down - not sure it gives us all too much new information\n",
    "    up_minus_down_conditions = [\n",
    "        (input_df.loc[:,'requester_upvotes_minus_downvotes_at_request']==0),\n",
    "        (input_df.loc[:,'requester_upvotes_minus_downvotes_at_request']<0),\n",
    "        (input_df.loc[:,'requester_upvotes_minus_downvotes_at_request']>0)]\n",
    "    up_minus_down_choices = ['ignored', 'disliked', 'liked']\n",
    "    output_df['up_minus_down_cat'] = np.select(up_minus_down_conditions, up_minus_down_choices, default='na')\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat = add_profile_features(input_df = train_df,\n",
    "                                      output_df = train_feat_mat)\n",
    "\n",
    "dev_feat_mat = add_profile_features(input_df = dev_df,\n",
    "                                    output_df = dev_feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age of Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "# Age of account - whether it appears to be a new/throwaway account or a longtime veteran\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(train_feat_mat.loc[train_feat_mat['requester_account_age_in_days_at_request']!=0, 'requester_account_age_in_days_at_request']);\n",
    "# Create new variable for: first (days = 0), new (days <= median for nonzero), old (days > median for nonzero)\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x = 'account_age_cat', data = train_feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First/Repeat Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "# Days since request\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(train_feat_mat.loc[train_feat_mat['requester_days_since_first_post_on_raop_at_request']!=0, 'requester_days_since_first_post_on_raop_at_request']);\n",
    "# Create new variable for: first (days = 0), repeat (days > 0)\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='first_repeat_requester', data = train_feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "# Number of RAOP comments\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(train_feat_mat.loc[train_feat_mat['requester_number_of_comments_in_raop_at_request']!=0, 'requester_number_of_comments_in_raop_at_request']);\n",
    "# Create new variable for: never (comments = 0), has (comments > 0)\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x = 'comments_raop_cat', data = train_feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up/Down Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "# Up Plus Down\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(train_feat_mat.loc[:,'requester_upvotes_plus_downvotes_at_request']);\n",
    "# Up Plus Down Cat\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(x = 'up_plus_down_cat', data = train_feat_mat)\n",
    "\n",
    "# Up Minus Down\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(train_feat_mat.loc[:,'requester_upvotes_minus_downvotes_at_request']);\n",
    "# Up Minus Down Cat\n",
    "plt.subplot(2,2,4)\n",
    "sns.countplot(x = 'up_minus_down_cat', data = train_feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_textual\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Textual Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Analysis Plan (AW + SB)\n",
    "* Sentiment analysis\n",
    "* Check whether the post matches with the Sub-Reddits the original poster subscribed\n",
    "* Number of capitalized words\n",
    "\n",
    "Methods:  \n",
    "\n",
    "\n",
    "- Bag-of-words = base methodology  \n",
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.\n",
    "\n",
    "- Topic modelling = potential\n",
    "Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic.\n",
    "\n",
    "- Stemming/Pre-Processing = potential (see dimensionality reduction)  \n",
    "The idea of stemming is a sort of normalizing method. Many variations of words carry the same meaning, other than when tense is involved. The reason why we stem is to shorten the lookup, and normalize sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Stanford paper, we read the part regarding narratives found in the posts and thus, we create features that identify words for each narrative in a given observation and calculate the feature for each narrative as a total count of the words in a given narrative in the text and divide by total text length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = [\"money\", \"now\", \"broke\", \"week\", \"until\", \"time\",\n",
    "          \"last\", \"day\", \"when\", \"today\", \"tonight\", \"paid\", \"next\",\n",
    "          \"first\", \"night\", \"after\", \"tomorrow\", \"month\", \"while\",\n",
    "          \"account\", \"before\", \"long\", \"friday\", \"rent\", \"buy\",\n",
    "          \"bank\", \"still\", \"bills\", \"ago\", \"cash\", \"due\",\n",
    "          \"soon\", \"past\", \"never\", \"paycheck\", \"check\", \"spent\",\n",
    "          \"years\", \"poor\", \"till\", \"yesterday\", \"morning\", \"dollars\",\n",
    "          \"financial\", \"hour\", \"bill\", \"evening\", \"credit\",\n",
    "          \"budget\", \"loan\", \"bucks\", \"deposit\", \"dollar\", \"current\",\n",
    "          \"payed\"]\n",
    "\n",
    "job = [\"work\", \"job\", \"paycheck\", \"unemployment\", \"interview\",\n",
    "          \"fired\", \"employment\", \"hired\", \"hire\"]\n",
    "\n",
    "student = [\"college\", \"student\", \"school\", \"roommate\",\n",
    "          \"studying\", \"university\", \"finals\", \"semester\",\n",
    "          \"class\", \"study\", \"project\", \"dorm\", \"tuition\"]\n",
    "\n",
    "family = [\"family\", \"mom\", \"wife\", \"parents\", \"mother\", \"husband\",\n",
    "           \"dad\", \"son\", \"daughter\", \"father\", \"parent\",\n",
    "           \"mum\"]\n",
    "\n",
    "craving = [\"friend\", \"girlfriend\", \"craving\", \"birthday\",\n",
    "          \"boyfriend\", \"celebrate\", \"party\", \"game\", \"games\",\n",
    "          \"movie\", \"date\", \"drunk\", \"beer\", \"celebrating\", \"invited\",\n",
    "          \"drinks\", \"crave\", \"wasted\", \"invite\"]\n",
    "\n",
    "narratives = [money, job, student, family, craving]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(s):\n",
    "    s = re.sub(\"[^\\w']|_\", \" \", s) \n",
    "    s = s.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "    s = re.sub(' +',' ', s)\n",
    "    s = s.lower()    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_narrative(narr,s):\n",
    "    count = 0\n",
    "    for word in narr:\n",
    "        count += s.split().count(word)\n",
    "    return count/len(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_narrative_features(data): \n",
    "    data['post_and_title'] = data['request_text_edit_aware'] + ' ' + data['request_title']\n",
    "    clean_text = data['post_and_title'].apply(lambda s: pre_process(s))\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    for n in narratives:\n",
    "        features[n[0]] = clean_text.apply(lambda s: find_narrative(n,s))\n",
    "    return features\n",
    "\n",
    "# train_narrative_features = construct_narrative_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pyenchant library, we create a function that does a spellcheck on the title and request text. In detail, we look at the spelling error ratio as the number of misspellings divided by the square root of the length of the text. The square root is taken so that longer texts don't overly diminish the number of errors in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_error_ratio(text, spellchecker = SpellChecker(\"en_US\")):\n",
    "    error_count = 0\n",
    "    spellchecker.set_text(text)\n",
    "    \n",
    "    for error in spellchecker:\n",
    "        error_count += 1\n",
    "\n",
    "    len_text = len(text.split())\n",
    "    if len_text == 0:\n",
    "        err_ratio = 0.5\n",
    "    else:\n",
    "        err_ratio = error_count / np.sqrt(len_text)\n",
    "\n",
    "    return err_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_features(input_df, output_df):    \n",
    "    # Combine the title and text into one\n",
    "    input_df['post_and_title'] = input_df['request_text_edit_aware'] + ' ' + input_df['request_title']\n",
    "    \n",
    "    # Pre-process the data\n",
    "    output_df['post_and_title'] = input_df['post_and_title'].apply(lambda s: pre_process(s))\n",
    "    \n",
    "    # Construct the narrative\n",
    "    for n in narratives:\n",
    "        output_df[n[0]] = input_df['post_and_title'].apply(lambda s: find_narrative(n,s))\n",
    "        \n",
    "    # Check if user indicated in text about giving back to community in some way\n",
    "    output_df['reciprocity'] = input_df['post_and_title'].apply(\n",
    "        lambda x:1 if re.search(\"repay|pay.+back|pay.+forward|return.+favor|favour\", x) else 0)\n",
    "\n",
    "    # Check if there is an image in the text or not\n",
    "    output_df['image_in_text'] = input_df['post_and_title'].str.contains(\n",
    "        'imgur.com|.jpg|.png|.jpeg|http', case = False).apply(lambda x: 1 if x else 0)\n",
    "    \n",
    "    # Check if a user is polite\n",
    "    output_df['politeness'] = input_df['post_and_title'].apply(\n",
    "        lambda x: 1 if re.search(\"thank|appreciate|advance\", x) else 0)\n",
    "    \n",
    "    # Spelling Error in the title\n",
    "    output_df['spell_err_title'] = input_df['request_title'].apply(\n",
    "        lambda x:spell_error_ratio(x))\n",
    "    \n",
    "    # Spelling Error in the request text\n",
    "    output_df['spell_err_post'] = input_df['request_text_edit_aware'].apply(\n",
    "        lambda x: spell_error_ratio(x))\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat = add_text_features(input_df = train_df,\n",
    "                    output_df = train_feat_mat)\n",
    "\n",
    "dev_feat_mat = add_text_features(input_df = dev_df,\n",
    "                    output_df = dev_feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count the number of words capitalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capitalization typically conveys stronger emotion and creates emphasis on certain parts of the sentence. We are interested in learning whether capitalization in the request text has any effect in one's chance of receiving the pizza.  \n",
    "In counting the number of words capitalized, we exclude state abbreviations and a few other common abbreviations as they do not have the effect of stronger emotion or emphasis that we try to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the target variable and two text fields\n",
    "i = 1\n",
    "\n",
    "Y_train_np = train_df['requester_received_pizza'].values\n",
    "print(Y_train_np[i])\n",
    "\n",
    "request_text_edit_aware_train_np = train_df['request_text_edit_aware'].values\n",
    "print(request_text_edit_aware_train_np[i])\n",
    "\n",
    "request_title_train_np = train_df['request_title'].values\n",
    "print(request_title_train_np[i])\n",
    "\n",
    "requester_subreddits_at_request_train_np = train_df['requester_subreddits_at_request'].values\n",
    "print(requester_subreddits_at_request_train_np[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateAbbrList = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
    "otherExlcusionList = ['US', 'PS', 'EDIT', 'PM']\n",
    "capCountList = []\n",
    "capCategoryList = []\n",
    "for i in range(len(request_text_edit_aware_train_np)):\n",
    "    msg = request_text_edit_aware_train_np[i]\n",
    "    ## Replace special characters with space\n",
    "    msg = re.sub('[^1-9a-zA-Z\\s]+', '', msg)\n",
    "    capCount = 0\n",
    "    for word in msg.split():\n",
    "        ## Remove if a word has only 1 character (i.e., 'I')\n",
    "        if len(word) > 1:\n",
    "            if word.isupper() and word not in stateAbbrList and word not in otherExlcusionList:\n",
    "                #print(word)\n",
    "                capCount += 1\n",
    "        \n",
    "    capCountList.append(capCount)\n",
    "#print(capCountList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avaerge target in training by the number of capitalized words\n",
    "Y_byCapCount = pd.DataFrame(Y_train_np).groupby(capCountList).mean()\n",
    "## Total number of observations by the number of capitalized words\n",
    "n_byCapCount = pd.DataFrame(Y_train_np).groupby(capCountList).count()\n",
    "print('Below shows the average percentage of pizza requests fulfilled by the number of capitalized words in the request text:')\n",
    "print(Y_byCapCount)\n",
    "\n",
    "fig = plt.figure()\n",
    "## Specify the dimensions [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.4, 0.8, 0.4],\n",
    "                   xticklabels=[], ylim=(0, 1))\n",
    "ax2 = fig.add_axes([0.1, 0.1, 0.8, 0.25],\n",
    "                   ylim=(0, 2000))\n",
    "\n",
    "ax1.plot(np.unique(capCountList), Y_byCapCount)\n",
    "ax1.set_ylabel('% of Pizzas Given')\n",
    "ax2.hist(capCountList, 120)\n",
    "ax2.set_ylabel('# of Requesters')\n",
    "ax2.set_xlabel('# of Capitalized Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top line chart shows the the average percentage of pizza requests fulfilled by the number of capitalized words in the request text. The averages change radically as the number of capitalized words increase. This is not surprising since the majority of requests doesn't have any word capitalized. So we decided to bin this feature into two categories: no capitalized word (0) and at least one capitalized word (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bin into 2 categories: Capitalization (Yes, No)\n",
    "capCategoryList = np.where(np.asarray(capCountList)>=1, 1, 0)\n",
    "\n",
    "## Avaerge target in training by the number of capCategory\n",
    "Y_byCapCategory = pd.DataFrame(Y_train_np).groupby(capCategoryList).mean()\n",
    "## Total number of observations by the number of capCategory\n",
    "n_byCapCategory = pd.DataFrame(Y_train_np).groupby(capCategoryList).count()\n",
    "print('Among the requests without any capitalized word, ' + '{:.1%}'.format(Y_byCapCategory[0][0]) + ' of them were fulfilled.')\n",
    "print('Among the requests with at least one capitalized word, ' + '{:.1%}'.format(Y_byCapCategory[0][1]) + ' of them were fulfilled.')\n",
    "print('There are %i requests without any capitalized word.' %n_byCapCategory[0][0])\n",
    "print('There are %i requests with at least one capitalized word.' %n_byCapCategory[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference: https://www.nltk.org/api/nltk.sentiment.html (CITATION NEEDED)\n",
    "## Reference: http://www.nltk.org/howto/sentiment.html\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "neuList = []\n",
    "posList = []\n",
    "negList = []\n",
    "compoundSenList = []\n",
    "\n",
    "for i in range(len(request_text_edit_aware_train_np)):\n",
    "    msg = request_text_edit_aware_train_np[i] \n",
    "    ss = sid.polarity_scores(msg)\n",
    "    neuList.append(ss['neu'])\n",
    "    posList.append(ss['pos'])\n",
    "    negList.append(ss['neg'])\n",
    "    compoundSenList.append(ss['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(np.asarray(neuList), bins=[0, 0.25, 0.5, 0.75, 1])\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "#n, bins, patches = ax[1,1].hist(np.asarray(neuList), 10, density=1)\n",
    "ax[0,0].hist(np.asarray(neuList))\n",
    "ax[0,0].set_title('Histogram of Neutral Score')\n",
    "ax[0,1].hist(np.asarray(posList))\n",
    "ax[0,1].set_title('Histogram of Positive Score')\n",
    "ax[1,0].hist(np.asarray(negList))\n",
    "ax[1,0].set_title('Histogram of Negative Score')\n",
    "ax[1,1].hist(np.asarray(compoundSenList))\n",
    "ax[1,1].set_title('Histogram of Compound Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticReg:\n",
    "    \"\"\"\n",
    "    Wrapper Class for Logistic Regression which has the usual sklearn instance \n",
    "    in an attribute self.model, and pvalues, z scores and estimated \n",
    "    errors for each coefficient in \n",
    "    \n",
    "    self.z_scores\n",
    "    self.p_values\n",
    "    self.sigma_estimates\n",
    "    \n",
    "    as well as the negative hessian of the log Likelihood (Fisher information)\n",
    "    \n",
    "    self.F_ij\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):#,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args,**kwargs)#,**args)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.model.fit(X,y)\n",
    "        #### Get p-values for the fitted model ####\n",
    "        denom = (2.0*(1.0+np.cosh(self.model.decision_function(X))))\n",
    "        denom = np.tile(denom,(X.shape[1],1)).T\n",
    "        F_ij = np.dot((X/denom).T,X) ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0]/sigma_estimates # z-score for eaach model coefficient\n",
    "        p_values = [stat.norm.sf(abs(x))*2 for x in z_scores] ### two tailed test for p-values\n",
    "        \n",
    "        self.coef_ = self.model.coef_\n",
    "        self.z_scores = z_scores\n",
    "        self.p_values = p_values\n",
    "        self.sigma_estimates = sigma_estimates\n",
    "        self.F_ij = F_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentX = np.c_[np.asarray(neuList), np.asarray(posList), np.asarray(negList), np.asarray(compoundSenList)]\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "lgModel = LogisticReg()\n",
    "lgModel.fit(sentimentX, Y_train_np)\n",
    "print(lgModel.coef_)\n",
    "print(lgModel.p_values)\n",
    "\n",
    "## Note only neutral score and compound score are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of words in a request text\n",
    "wordCountList = []\n",
    "\n",
    "for i in range(len(request_text_edit_aware_train_np)):\n",
    "    msg = request_text_edit_aware_train_np[i] \n",
    "    wordCountList.append(len(re.findall(r'\\w+', msg)))\n",
    "\n",
    "wordCountList_np = np.asarray(wordCountList)\n",
    "\n",
    "## There are a few cases where word counts are less than 10, investigate more\n",
    "print(np.where(wordCountList_np < 10))\n",
    "print(request_text_edit_aware_train_np[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot word count for each request\n",
    "plt.scatter(np.asarray(range(len(wordCountList)))[Y_train_np==False], wordCountList_np[Y_train_np==False], c='black', s=1, label=\"Didn't Receive Pizza\")\n",
    "plt.scatter(np.asarray(range(len(wordCountList)))[Y_train_np==True], wordCountList_np[Y_train_np==True], c='red', s=1, label=\"Received Pizza\")\n",
    "plt.xlabel('Request Text #')\n",
    "plt.ylabel('Word Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatterplot above, we cannot observe an obvious pattern whether longer request texts contribute to a higher or lower chance of getting a pizza. So we try to visualize it after sorting the word count from low to high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot word count for each request after sorting\n",
    "srt_indices = np.argsort(wordCountList_np)\n",
    "Y_train_srt = []\n",
    "test = []\n",
    "for i in range(len(wordCountList_np)):\n",
    "    Y_train_srt.append(Y_train_np[srt_indices[i]])\n",
    "\n",
    "wordCountList_srt_np = np.sort(wordCountList_np)\n",
    "Y_train_srt_np = np.asarray(Y_train_srt)\n",
    "plt.scatter(np.asarray(range(len(wordCountList)))[Y_train_srt_np==False], wordCountList_srt_np[Y_train_srt_np==False], c='black', s=1, label=\"Didn't Receive Pizza\")\n",
    "plt.scatter(np.asarray(range(len(wordCountList)))[Y_train_srt_np==True], wordCountList_srt_np[Y_train_srt_np==True], c='red', s=1, label=\"Received Pizza\")\n",
    "plt.xlabel('Sort')\n",
    "plt.ylabel('Word Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word count is low, we see black dots more frequently. This indicates that lower word counts might result in a lower chance of getting a pizza. We plot a histogram of word count below to see whether there are natural breakpoints in word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wordCountList_np, bins =100, normed=True)\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram seems to a mixture of three Gaussian distributions, with means around 50, 170, and 400.  \n",
    "Build a 3-component Gaussian Mixture Model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(random_state=0, n_components=3)\n",
    "gmm.fit(wordCountList_np.reshape(-1, 1))\n",
    "\n",
    "wordCountCategory = gmm.predict(wordCountList_np.reshape(-1, 1))\n",
    "\n",
    "wordCount_byWordCountCategory = pd.DataFrame(wordCountList).groupby(wordCountCategory).mean()\n",
    "print('Average Word Count by GMM component:')\n",
    "print(wordCount_byWordCountCategory)\n",
    "print('\\n')\n",
    "\n",
    "Y_byWordCountCategory = pd.DataFrame(Y_train_np).groupby(wordCountCategory).mean()\n",
    "print('Percentage of requests fulfilled by GMM component:')\n",
    "print(Y_byWordCountCategory)\n",
    "print('\\n')\n",
    "\n",
    "n_byWordCountCategory = pd.DataFrame(Y_train_np).groupby(wordCountCategory).count()\n",
    "print('# of requests by GMM component:')\n",
    "print(n_byWordCountCategory)\n",
    "\n",
    "gmm_x = np.linspace(0, 900, 901)\n",
    "gmm_y = np.exp(gmm.score_samples(gmm_x.reshape(-1,1)))\n",
    "\n",
    "plt.hist(wordCountList_np, bins = 100, normed=True)\n",
    "plt.plot(gmm_x, gmm_y, color=\"crimson\", lw=2, label=\"GMM\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the average word count by GMM component, we label Component 0-2 as medium, high, and low word count category respectively. Medium and high word count requests have much higher chance of getting fulfilled than low word count requests. However, there are only 77 requests in the training set that's classified as high word count and the likelihood of receiving a pizza is not significantly different for high word count requests from medium word count requests. To avoid overfitting, we decide to group medium and high word count together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountCategoryGrp_List = []\n",
    "for i in range(len(wordCountCategory)):\n",
    "    if (wordCountCategory[i]==0) or (wordCountCategory[i]==1):\n",
    "        wordCountCategoryGrp_List.append(1)\n",
    "    else:\n",
    "        wordCountCategoryGrp_List.append(0)\n",
    "\n",
    "Y_byWordCountCategory = pd.DataFrame(Y_train_np).groupby(wordCountCategoryGrp_List).mean()\n",
    "print('Percentage of requests fulfilled by GMM component (after grouping):')\n",
    "print(Y_byWordCountCategory)\n",
    "print('\\n')\n",
    "\n",
    "n_byWordCountCategory = pd.DataFrame(Y_train_np).groupby(wordCountCategoryGrp_List).count()\n",
    "print('# of requests by GMM component (after grouping):')\n",
    "print(n_byWordCountCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features_A(df_in):\n",
    "    request_text_edit_aware_np = df_in['request_text_edit_aware'].values\n",
    "    stateAbbrList = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
    "    otherExlcusionList = ['US', 'PS', 'EDIT', 'PM']\n",
    "\n",
    "    capCategoryList = []\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    compoundSenList = []\n",
    "    ## Count the number of words in a request text\n",
    "    wordCountList = []\n",
    "\n",
    "    for i in range(len(request_text_edit_aware_np)):\n",
    "        msg = request_text_edit_aware_np[i]\n",
    "        ss = sid.polarity_scores(msg)\n",
    "        compoundSenList.append(ss['compound'])\n",
    "        wordCountList.append(len(re.findall(r'\\w+', msg)))\n",
    "        ## Remove special characters\n",
    "        msg = re.sub('[^1-9a-zA-Z\\s]+', '', msg)\n",
    "        capCount = 0\n",
    "        for word in msg.split():\n",
    "            ## Remove if a word has only 1 character (i.e., 'I')\n",
    "            if len(word) > 1:\n",
    "                if word.isupper() and word not in stateAbbrList and word not in otherExlcusionList:\n",
    "                    capCount += 1\n",
    "        if capCount == 0:\n",
    "            capCategory = 0\n",
    "        else:\n",
    "            capCategory = 1\n",
    "\n",
    "        capCategoryList.append(capCategory)\n",
    "\n",
    "    df2 = pd.DataFrame(capCategoryList, columns=['capCategory'])\n",
    "    df3 = pd.DataFrame(compoundSenList, columns=['compoundSen'])\n",
    "    wordCountList_np = np.asarray(wordCountList)\n",
    "    wordCountCategory = gmm.predict(wordCountList_np.reshape(-1, 1))\n",
    "    wordCountCategoryGrp_List = []\n",
    "    for i in range(len(wordCountCategory)):\n",
    "        if (wordCountCategory[i]==0) or (wordCountCategory[i]==1):\n",
    "            wordCountCategoryGrp_List.append(1)\n",
    "        else:\n",
    "            wordCountCategoryGrp_List.append(0)\n",
    "    df4 = pd.DataFrame(wordCountCategoryGrp_List, columns=['wordCountCategory'])\n",
    "\n",
    "    print(df_in.shape)\n",
    "    print(df2.shape)\n",
    "    print(df3.shape)\n",
    "    print(df4.shape)\n",
    "    df_out = pd.concat([df_in, df2, df3, df4], axis=1)\n",
    "    print(df_out.shape)\n",
    "\n",
    "    return df_out\n",
    "\n",
    "new_train_df = text_features_A(org_train_df)\n",
    "new_test_df = text_features_A(org_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sartaj's attempt to unify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_more_text_features(input_df, output_df):\n",
    "    request_text_edit_aware_np = input_df['request_text_edit_aware'].values\n",
    "    stateAbbrList = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
    "    otherExlcusionList = ['US', 'PS', 'EDIT', 'PM']\n",
    "\n",
    "    capCategoryList = []\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    compoundSenList = []\n",
    "\n",
    "    ## Count the number of words in a request text\n",
    "    wordCountList = []\n",
    "\n",
    "    for i in range(len(request_text_edit_aware_np)):\n",
    "        msg = request_text_edit_aware_np[i]\n",
    "        ss = sid.polarity_scores(msg)\n",
    "        compoundSenList.append(ss['compound'])\n",
    "        wordCountList.append(len(re.findall(r'\\w+', msg)))\n",
    "        \n",
    "        ## Remove special characters\n",
    "        msg = re.sub('[^1-9a-zA-Z\\s]+', '', msg)\n",
    "        capCount = 0\n",
    "        for word in msg.split():\n",
    "            ## Remove if a word has only 1 character (i.e., 'I')\n",
    "            if len(word) > 1:\n",
    "                if word.isupper() and word not in stateAbbrList and word not in otherExlcusionList:\n",
    "                    capCount += 1\n",
    "        if capCount == 0:\n",
    "            capCategory = 0\n",
    "        else:\n",
    "            capCategory = 1\n",
    "\n",
    "        capCategoryList.append(capCategory)\n",
    "\n",
    "    wordCountList_np = np.asarray(wordCountList)\n",
    "    wordCountCategory = gmm.predict(wordCountList_np.reshape(-1, 1))\n",
    "    wordCountCategoryGrp_List = []\n",
    "    for i in range(len(wordCountCategory)):\n",
    "        if (wordCountCategory[i]==0) or (wordCountCategory[i]==1):\n",
    "            wordCountCategoryGrp_List.append(1)\n",
    "        else:\n",
    "            wordCountCategoryGrp_List.append(0)\n",
    "\n",
    "    output_df['capCategory'] = capCategoryList\n",
    "    output_df['compoundSen'] = compoundSenList\n",
    "    output_df['wordCountCategory'] = wordCountCategoryGrp_List\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat = add_more_text_features(input_df = train_df,\n",
    "                    output_df = train_feat_mat)\n",
    "\n",
    "dev_feat_mat = add_more_text_features(input_df = dev_df,\n",
    "                    output_df = dev_feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text features from the post text by generating features from words\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             ngram_range = (1,2), \n",
    "                             preprocessor = pre_process,\n",
    "                             stop_words = 'english',\n",
    "                             norm = 'l2',\n",
    "                             sublinear_tf = True)\n",
    "\n",
    "train_bag_of_words = vectorizer.fit_transform(train_df_textual['post_and_title'])\n",
    "dev_bag_of_words = vectorizer.transform(dev_df_textual['post_and_title'])\n",
    "\n",
    "print(train_bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Logistic Regression with l1 penalty to feature select from our bag of words in order to reduce dimension.\n",
    "lr = LogisticRegression(C = 1,\n",
    "                        penalty = 'l1').fit(train_bag_of_words,train_labels)\n",
    "model = SelectFromModel(lr, prefit=True)\n",
    "\n",
    "train_pruned_bow = model.transform(train_bag_of_words)\n",
    "print(train_pruned_bow.shape)\n",
    "\n",
    "dev_pruned_bow=model.transform(dev_bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_lda = CountVectorizer(min_df = 10,\n",
    "                                 ngram_range = (1,1), \n",
    "                                 preprocessor = pre_process,\n",
    "                                 stop_words = 'english')\n",
    "\n",
    "lda_bag_of_words = vectorizer_lda.fit_transform(train_df_textual['post_and_title'])\n",
    "lda_devbag_of_words = vectorizer_lda.transform(dev_df_textual['post_and_title'])\n",
    "\n",
    "print(lda_bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components = 3, \n",
    "          learning_method='batch',\n",
    "          max_iter=30,\n",
    "          learning_decay=.7, \n",
    "          random_state=42)\n",
    "\n",
    "train_topics = lda.fit_transform(lda_bag_of_words)\n",
    "print(lda.components_.shape)\n",
    "\n",
    "dev_topics=lda.transform(lda_devbag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95, \n",
    "    min_df=2, \n",
    "    stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(train_df_textual['post_and_title'])\n",
    "dev_tfidf = tfidf_vectorizer.transform(dev_df_textual['post_and_title'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 3\n",
    "\n",
    "# Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, \n",
    "                random_state=1, \n",
    "                alpha=.1, \n",
    "                l1_ratio=.5, \n",
    "                init='nndsvd').fit(tfidf)\n",
    "\n",
    "nmf_train = nmf_model.transform(tfidf)\n",
    "nmf_dev = nmf_model.transform(dev_tfidf)\n",
    "\n",
    "print(nmf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: ONE DATAFRAME\n",
    "\n",
    "How do we combine features? Add to Feature Engineering Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEV DATA Only  \n",
    "\n",
    "Models we plan to test:\n",
    "- Logistic Regression\n",
    "Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables. This is highly applicable in this scenario due to the binary nature of our data. \n",
    "\n",
    "- Naive Bayes  \n",
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. The independence assumption helps in making a non-biased prediction for our model. \n",
    "\n",
    "- Decision Trees / Random Forest\n",
    "Random Forest or Random Decision Trees is a supervised learning algorithm. The „forest“ it builds, is an ensemble of Decision Trees, most of the time trained with the “bagging” method. The general idea of the bagging method is that a combination of learning models increases the overall result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mnb\"></a>\n",
    "### 6.1 Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mlr\"></a>\n",
    "### 6.2 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mxg\"></a>\n",
    "### 6.3 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "### HOLD ###- until we have final cleaned dataset\n",
    "\n",
    "# train_xgb = xgb.DMatrix(train_concat, label = train_labels)\n",
    "# dev_xgb = xgb.DMatrix(dev_concat)\n",
    "\n",
    "# # Specify parameters via map\n",
    "# xgb_params = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "# xgb_num_round = 2\n",
    "# xgb_base = xgb.train(xgb_params, train_xgb, xgb_num_round)\n",
    "\n",
    "# # Prediction\n",
    "# xgb_dev_prob = xgb_base.predict(dev_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning\"></a>\n",
    "### 6.4 Model Tuning\n",
    "\n",
    "Based on preliminary results, we will focus on the most promising model and begin to refine and tune that method.  \n",
    "\n",
    "There are two sets of hyperparameters which we will be able to adjust in pursuit of a more accurate model:  \n",
    "- **Model Parameters** _(will be dependent on which is our final model)_\n",
    "    - Logistic Regression\n",
    "        * `solver` - Will seek to find the optimal solver given the data size and feature dentiy (newton-cg, lbfgs, liblinear, sag, or saga)\n",
    "        * `penalty` - Select norm for penalization (l1 or l2)\n",
    "        * `C` - Adjust to reduce overfitting\n",
    "        * `tol` & `max_iter` - Deal with convergence issues\n",
    "    - Naive Bayes (BernoulliNB)\n",
    "        * `alpha` - Adjust smoothing for issues with sparse data\n",
    "    - Decision Trees / Random Forest\n",
    "        * `max_depth` & `n_estimators` - Achieve parsimonious level of detail in the forest\n",
    "        * `criterion` - Adjust method for determining the quality of each split (gini or entropy)\n",
    "- **Feature Engineering Parameters**\n",
    "    - Dimensionality reduction\n",
    "        * `analyzer` - Find optimal unit of observation for feature creation\n",
    "        * `vocabulary` - Create a more limited vocabulary using logistic regression with l1 penalty to identify and remove features with low or 0 weight\n",
    "        * `min_df` - Limit reliance on rare words without losing predictive power  \n",
    "        * `stop_words` - Remove overly-common words\n",
    "    - Error Review\n",
    "        * `pre-processor` - Create custom pre-processing algorithm to remove/edit idiosynchratic at-issue words/phrases found in review of false negatives/positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"error\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Analysis\n",
    "\n",
    "In the error analysis phase, we can compare our three models against each other on their Mis-classification rates i.e How many of our Predicted Labels don't match up to our dev labels. \n",
    "\n",
    "This can be found using a generic formula where: \n",
    "misclassified_model = np.where(dev_labels != dev_preds)\n",
    "\n",
    "\n",
    "**TO DO:** What we're getting wrong to figure out idiosyncratic issues: \n",
    "Identify the error themes. Can mis-classification be addressed? \n",
    "Error Analysis Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results / Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an optimal model has been build with training data and tested with dev data, we will run the test data through the model and output a predicted class (boolean, pizza received or not).  \n",
    "This test result will be _submitted via csv to Kaggle_, which will return an accuracy score.  \n",
    "This accuracy score will be compared against the benchmark ZeroR score to evaluate the predictive power of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
